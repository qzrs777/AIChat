import os
import sys
import traceback
from typing import Generator, Union
import numpy as np
import soundfile as sf
from io import BytesIO

now_dir = os.getcwd()
sys.path.append(now_dir)
sys.path.append("%s/GPT_SoVITS" % (now_dir))

import argparse
import subprocess
import wave
import signal
import numpy as np
import soundfile as sf
from fastapi import UploadFile, File
from fastapi import FastAPI, Response
from fastapi.responses import StreamingResponse, JSONResponse
import uvicorn
from io import BytesIO

from faster_whisper import WhisperModel
import tempfile
import shutil

from tools.i18n.i18n import I18nAuto
from GPT_SoVITS.TTS_infer_pack.TTS import TTS, TTS_Config
from GPT_SoVITS.TTS_infer_pack.text_segmentation_method import get_method_names as get_cut_method_names
from pydantic import BaseModel
import threading


# print(sys.path)
i18n = I18nAuto()
cut_method_names = get_cut_method_names()

parser = argparse.ArgumentParser(description="GPT-SoVITS api")
parser.add_argument("-c", "--tts_config", type=str, default="GPT_SoVITS/configs/tts_infer.yaml", help="tts_inferè·¯å¾„")
parser.add_argument("-a", "--bind_addr", type=str, default="127.0.0.1", help="default: 127.0.0.1")
parser.add_argument("-p", "--port", type=int, default="9880", help="default: 9880")
args = parser.parse_args()
config_path = args.tts_config
# device = args.device
port = args.port
host = args.bind_addr
argv = sys.argv

if config_path in [None, ""]:
    config_path = "GPT-SoVITS/configs/tts_infer.yaml"

tts_config = TTS_Config(config_path)
print(tts_config)
tts_pipeline = TTS(tts_config)

print("æ­£åœ¨åŠ è½½ Whisper ASR æ¨¡å‹...")
### å¯é€‰tiny, base, small, medium, large-v3-turboç­‰ç­‰, tiny (VRAM<0.5GB) base small VRAM 0.5-0.8å·¦å³
asr_model_size = "small"
try:
    # device="cuda" ä½¿ç”¨æ˜¾å¡, ä¹Ÿå¯ä½¿ç”¨'cpu', smallåŠä»¥ä¸‹æ¨¡å‹å¯ä»¥åœ¨æ ‘è“æ´¾ä¸ŠæˆåŠŸè¿è¡Œ
    # compute_type="int8_float16" ç²¾åº¦ä¸é”™ä¸”æçœæ˜¾å­˜
    asr_model = WhisperModel(
        asr_model_size, 
        device="cuda", 
        compute_type="int8_float16"
    )
    print(f"Whisper ({asr_model_size}) åŠ è½½å®Œæˆ")
except Exception as e:
    print(f"ASR æ¨¡å‹åŠ è½½å¤±è´¥ (å¯èƒ½æ˜¾å­˜ä¸è¶³æˆ–ç¼ºå°‘åº“): {e}")
    print("ASR åŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œä½† TTS ä»å¯æ­£å¸¸å·¥ä½œã€‚")
    asr_model = None

APP = FastAPI()

def get_silent_wav(duration=0.5, sr=32000):
    """
    ç”Ÿæˆä¸€æ®µæŒ‡å®šæ—¶é•¿çš„é™éŸ³ WAV æ•°æ®
    """
    # ç”Ÿæˆå…¨ 0 çš„æ•°ç»„ (é™éŸ³)
    silent_data = np.zeros(int(sr * duration), dtype=np.int16)
    buffer = BytesIO()
    sf.write(buffer, silent_data, sr, format="wav")
    return buffer.getvalue()


class TTS_Request(BaseModel):
    text: str = None
    text_lang: str = None
    ref_audio_path: str = None
    aux_ref_audio_paths: list = None
    prompt_lang: str = None
    prompt_text: str = ""
    top_k: int = 5
    top_p: float = 1
    temperature: float = 1
    text_split_method: str = "cut5"
    batch_size: int = 1
    batch_threshold: float = 0.75
    split_bucket: bool = True
    speed_factor: float = 1.0
    fragment_interval: float = 0.3
    seed: int = -1
    media_type: str = "wav"
    streaming_mode: Union[bool, int] = False
    parallel_infer: bool = True
    repetition_penalty: float = 1.35
    sample_steps: int = 32
    super_sampling: bool = False
    overlap_length: int = 2
    min_chunk_length: int = 16


def pack_ogg(io_buffer: BytesIO, data: np.ndarray, rate: int):
    # Author: AkagawaTsurunaki
    # Issue:
    #   Stack overflow probabilistically occurs
    #   when the function `sf_writef_short` of `libsndfile_64bit.dll` is called
    #   using the Python library `soundfile`
    # Note:
    #   This is an issue related to `libsndfile`, not this project itself.
    #   It happens when you generate a large audio tensor (about 499804 frames in my PC)
    #   and try to convert it to an ogg file.
    # Related:
    #   https://github.com/RVC-Boss/GPT-SoVITS/issues/1199
    #   https://github.com/libsndfile/libsndfile/issues/1023
    #   https://github.com/bastibe/python-soundfile/issues/396
    # Suggestion:
    #   Or split the whole audio data into smaller audio segment to avoid stack overflow?

    def handle_pack_ogg():
        with sf.SoundFile(io_buffer, mode="w", samplerate=rate, channels=1, format="ogg") as audio_file:
            audio_file.write(data)



    # See: https://docs.python.org/3/library/threading.html
    # The stack size of this thread is at least 32768
    # If stack overflow error still occurs, just modify the `stack_size`.
    # stack_size = n * 4096, where n should be a positive integer.
    # Here we chose n = 4096.
    stack_size = 4096 * 4096
    try:
        threading.stack_size(stack_size)
        pack_ogg_thread = threading.Thread(target=handle_pack_ogg)
        pack_ogg_thread.start()
        pack_ogg_thread.join()
    except RuntimeError as e:
        # If changing the thread stack size is unsupported, a RuntimeError is raised.
        print("RuntimeError: {}".format(e))
        print("Changing the thread stack size is unsupported.")
    except ValueError as e:
        # If the specified stack size is invalid, a ValueError is raised and the stack size is unmodified.
        print("ValueError: {}".format(e))
        print("The specified stack size is invalid.")

    return io_buffer


def pack_raw(io_buffer: BytesIO, data: np.ndarray, rate: int):
    io_buffer.write(data.tobytes())
    return io_buffer


def pack_wav(io_buffer: BytesIO, data: np.ndarray, rate: int):
    io_buffer = BytesIO()
    sf.write(io_buffer, data, rate, format="wav")
    return io_buffer


def pack_aac(io_buffer: BytesIO, data: np.ndarray, rate: int):
    process = subprocess.Popen(
        [
            "ffmpeg",
            "-f",
            "s16le",  # è¾“å…¥16ä½æœ‰ç¬¦å·å°ç«¯æ•´æ•°PCM
            "-ar",
            str(rate),  # è®¾ç½®é‡‡æ ·ç‡
            "-ac",
            "1",  # å•å£°é“
            "-i",
            "pipe:0",  # ä»ç®¡é“è¯»å–è¾“å…¥
            "-c:a",
            "aac",  # éŸ³é¢‘ç¼–ç å™¨ä¸ºAAC
            "-b:a",
            "192k",  # æ¯”ç‰¹ç‡
            "-vn",  # ä¸åŒ…å«è§†é¢‘
            "-f",
            "adts",  # è¾“å‡ºAACæ•°æ®æµæ ¼å¼
            "pipe:1",  # å°†è¾“å‡ºå†™å…¥ç®¡é“
        ],
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    )
    out, _ = process.communicate(input=data.tobytes())
    io_buffer.write(out)
    return io_buffer


def pack_audio(io_buffer: BytesIO, data: np.ndarray, rate: int, media_type: str):
    if media_type == "ogg":
        io_buffer = pack_ogg(io_buffer, data, rate)
    elif media_type == "aac":
        io_buffer = pack_aac(io_buffer, data, rate)
    elif media_type == "wav":
        io_buffer = pack_wav(io_buffer, data, rate)
    else:
        io_buffer = pack_raw(io_buffer, data, rate)
    io_buffer.seek(0)
    return io_buffer


# from https://huggingface.co/spaces/coqui/voice-chat-with-mistral/blob/main/app.py
def wave_header_chunk(frame_input=b"", channels=1, sample_width=2, sample_rate=32000):
    # This will create a wave header then append the frame input
    # It should be first on a streaming wav file
    # Other frames better should not have it (else you will hear some artifacts each chunk start)
    wav_buf = BytesIO()
    with wave.open(wav_buf, "wb") as vfout:
        vfout.setnchannels(channels)
        vfout.setsampwidth(sample_width)
        vfout.setframerate(sample_rate)
        vfout.writeframes(frame_input)

    wav_buf.seek(0)
    return wav_buf.read()


def handle_control(command: str):
    if command == "restart":
        os.execl(sys.executable, sys.executable, *argv)
    elif command == "exit":
        os.kill(os.getpid(), signal.SIGTERM)
        exit(0)


def check_params(req: dict):
    text: str = req.get("text", "")
    text_lang: str = req.get("text_lang", "")
    ref_audio_path: str = req.get("ref_audio_path", "")
    streaming_mode: bool = req.get("streaming_mode", False)
    media_type: str = req.get("media_type", "wav")
    prompt_lang: str = req.get("prompt_lang", "")
    text_split_method: str = req.get("text_split_method", "cut5")

    if ref_audio_path in [None, ""]:
        return JSONResponse(status_code=400, content={"message": "ref_audio_path is required"})
    if text in [None, ""]:
        return JSONResponse(status_code=400, content={"message": "text is required"})
    if text_lang in [None, ""]:
        return JSONResponse(status_code=400, content={"message": "text_lang is required"})
    elif text_lang.lower() not in tts_config.languages:
        return JSONResponse(
            status_code=400,
            content={"message": f"text_lang: {text_lang} is not supported in version {tts_config.version}"},
        )
    if prompt_lang in [None, ""]:
        return JSONResponse(status_code=400, content={"message": "prompt_lang is required"})
    elif prompt_lang.lower() not in tts_config.languages:
        return JSONResponse(
            status_code=400,
            content={"message": f"prompt_lang: {prompt_lang} is not supported in version {tts_config.version}"},
        )
    if media_type not in ["wav", "raw", "ogg", "aac"]:
        return JSONResponse(status_code=400, content={"message": f"media_type: {media_type} is not supported"})
    # elif media_type == "ogg" and not streaming_mode:
    #     return JSONResponse(status_code=400, content={"message": "ogg format is not supported in non-streaming mode"})

    if text_split_method not in cut_method_names:
        return JSONResponse(
            status_code=400, content={"message": f"text_split_method:{text_split_method} is not supported"}
        )

    return None


async def tts_handle(req: dict):
    """
    Text to speech handler.
    """
    # â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
    # ã€æ–°å¢è°ƒè¯•é€»è¾‘ Startã€‘
    # 1. è·å–åŸå§‹è·¯å¾„
    raw_ref_path = req.get("ref_audio_path", "")
    print(f"\n====== [è°ƒè¯•ä¿¡æ¯] æ”¶åˆ°æ–°è¯·æ±‚ ======")
    print(f"1. åŸå§‹è·¯å¾„: {raw_ref_path}")

    # 2. å¤„ç† Proton/Windows è·¯å¾„
    if raw_ref_path and (raw_ref_path.startswith("Z:") or raw_ref_path.startswith("z:")):
        # å»æ‰å‰ä¸¤ä¸ªå­—ç¬¦ (Z:)ï¼Œå¹¶å°† \ æ›¿æ¢ä¸º /
        clean_path = raw_ref_path[2:].replace("\\", "/")
        req["ref_audio_path"] = clean_path
        print(f"2. ä¿®æ­£è·¯å¾„: {clean_path}")
    else:
        clean_path = raw_ref_path

    # 3. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if clean_path and os.path.exists(clean_path):
        print(f"3. æ–‡ä»¶çŠ¶æ€: æ–‡ä»¶å­˜åœ¨ï¼Œå¯ä»¥è¯»å–")
    else:
        print(f"3. æ–‡ä»¶çŠ¶æ€: æ–‡ä»¶ä¸å­˜åœ¨! è¯·æ£€æŸ¥è·¯å¾„æˆ–æ–‡ä»¶åä¹±ç ")
        # å¯ä»¥åœ¨è¿™é‡Œå¼ºè¡Œæ›¿æ¢æˆä½ çš„å¤‡ç”¨æ–‡ä»¶ (å¯é€‰)
        # fallback_path = "/home/joeodagiri/sovits_ref/1.wav"
        # if os.path.exists(fallback_path):
        #     print(f"4. å·²å¯ç”¨å…œåº•æ–‡ä»¶: {fallback_path}")
        #     req["ref_audio_path"] = fallback_path

    print(f"====================================\n")
    # ã€æ–°å¢è°ƒè¯•é€»è¾‘ Endã€‘
    # â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²

    streaming_mode = req.get("streaming_mode", False)
    return_fragment = req.get("return_fragment", False)
    media_type = req.get("media_type", "wav")

    check_res = check_params(req)
    if check_res is not None:
        # æ‰“å°ä¸€ä¸‹å…·ä½“æ˜¯å“ªä¸ªå‚æ•°æ ¡éªŒå¤±è´¥äº†
        print(f"å‚æ•°æ ¡éªŒå¤±è´¥: {check_res.body}") 
        return check_res

    if streaming_mode == 0:
        streaming_mode = False
        return_fragment = False
        fixed_length_chunk = False
    elif streaming_mode == 1:
        streaming_mode = False
        return_fragment = True
        fixed_length_chunk = False
    elif streaming_mode == 2:
        streaming_mode = True
        return_fragment = False
        fixed_length_chunk = False
    elif streaming_mode == 3:
        streaming_mode = True
        return_fragment = False
        fixed_length_chunk = True

    else:
        return JSONResponse(status_code=400, content={"message": f"the value of streaming_mode must be 0, 1, 2, 3(int) or true/false(bool)"})

    req["streaming_mode"] = streaming_mode
    req["return_fragment"] = return_fragment
    req["fixed_length_chunk"] = fixed_length_chunk

    # print(f"{streaming_mode} {return_fragment} {fixed_length_chunk}") # è¿™ä¸€è¡Œå¯ä»¥æ³¨é‡Šæ‰ï¼Œä¸Šé¢å·²ç»æœ‰è¯¦ç»†æ—¥å¿—äº†

    streaming_mode = streaming_mode or return_fragment

    try:
        tts_generator = tts_pipeline.run(req)

        if streaming_mode:
            def streaming_generator(tts_generator: Generator, media_type: str):
                if_frist_chunk = True
                for sr, chunk in tts_generator:
                    if if_frist_chunk and media_type == "wav":
                        yield wave_header_chunk(sample_rate=sr)
                        media_type = "raw"
                        if_frist_chunk = False
                    yield pack_audio(BytesIO(), chunk, sr, media_type).getvalue()

            return StreamingResponse(
                streaming_generator(
                    tts_generator,
                    media_type,
                ),
                media_type=f"audio/{media_type}",
            )

        else:
            sr, audio_data = next(tts_generator)
            audio_data = pack_audio(BytesIO(), audio_data, sr, media_type).getvalue()
            return Response(audio_data, media_type=f"audio/{media_type}")
            
    except Exception as e:
        # â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼ ä¿®æ”¹è¿™é‡Œ â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
        
        # 1. åœ¨åå°æ‰“å°é”™è¯¯
        print(f"[é”™è¯¯å·²æ•è·] æ¨ç†å¤±è´¥ï¼Œå·²è‡ªåŠ¨æ›¿æ¢ä¸ºé™éŸ³ä»¥é˜²æ­¢æ¸¸æˆå¡æ­»ã€‚")
        print(f"é”™è¯¯è¯¦æƒ…: {e}")
        traceback.print_exc()

        # 2. ç”Ÿæˆä¸€æ®µ0.5ç§’çš„é™éŸ³,æ¸¸æˆæ’­æ”¾é™éŸ³åç»§ç»­æµç¨‹
        silent_wav = get_silent_wav(duration=0.5)
        
        # 3. è¿”å› 200 OKï¼Œæ¬ºéª—æ¸¸æˆè¯´"ç”±äºè¿™é‡Œå¤ªåµæˆ‘æ²¡å¬æ¸…"ï¼ˆå…¶å®æ˜¯æ²¡åˆæˆå‡ºæ¥ï¼‰
        return Response(content=silent_wav, media_type="audio/wav")

@APP.post("/asr")
async def asr_handle(file: UploadFile = File(...)):
    """
    æ¥æ”¶éŸ³é¢‘æ–‡ä»¶ -> è¿”å›è¯†åˆ«åˆ°çš„ä¸­æ–‡æ–‡æœ¬
    """
    # 1. æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŠ è½½
    if asr_model is None:
        return JSONResponse(status_code=500, content={"message": "ASR æ¨¡å‹æœªæˆåŠŸåŠ è½½ï¼Œè¯·æ£€æŸ¥åå°æ—¥å¿—"})

    temp_path = ""
    try:
        # 2. å°†ä¸Šä¼ çš„å†…å­˜æ–‡ä»¶ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶ (Whisper éœ€è¦è¯»å–ç‰©ç†æ–‡ä»¶è·¯å¾„)
        # delete=False è®©æˆ‘ä»¬æ‰‹åŠ¨æ§åˆ¶åˆ é™¤ï¼Œé˜²æ­¢ Windows/Wine ä¸‹çš„æ–‡ä»¶é”é—®é¢˜
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            shutil.copyfileobj(file.file, tmp)
            temp_path = tmp.name

        # 3. å¼€å§‹æ¨ç†
        # beam_size=1: è´ªå©ªè§£ç ï¼Œé€Ÿåº¦æœ€å¿«ï¼Œæ˜¾å­˜å ç”¨æœ€å°
        # language="zh": å¼ºåˆ¶è¯†åˆ«ä¸ºä¸­æ–‡
        # vad_filter=True: è‡ªåŠ¨åˆ‡é™¤é™éŸ³ç‰‡æ®µï¼Œæé«˜å‡†ç¡®ç‡
        segments, info = asr_model.transcribe(
            temp_path, 
            beam_size=1, 
            language="zh", 
            vad_filter=True
        )

        # 4. æ‹¼æ¥ç»“æœ (segments æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨)
        full_text = "".join([segment.text for segment in segments])
        
        # æ¸…ç†æ–‡æœ¬çš„å‰åç©ºæ ¼
        full_text = full_text.strip()

        print(f"ğŸ¤ [ASRè¯†åˆ«] è€—æ—¶: {info.duration:.2f}s | ç»“æœ: {full_text}")

        # è¿”å› JSON æ ¼å¼
        return JSONResponse(status_code=200, content={"text": full_text})

    except Exception as e:
        print(f"ASR è¯†åˆ«å‡ºé”™: {e}")
        return JSONResponse(status_code=500, content={"message": str(e)})
    
    finally:
        # 5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_path and os.path.exists(temp_path):
            try:
                os.remove(temp_path)
            except Exception:
                pass


@APP.get("/control")
async def control(command: str = None):
    if command is None:
        return JSONResponse(status_code=400, content={"message": "command is required"})
    handle_control(command)


@APP.get("/tts")
async def tts_get_endpoint(
    text: str = None,
    text_lang: str = None,
    ref_audio_path: str = None,
    aux_ref_audio_paths: list = None,
    prompt_lang: str = None,
    prompt_text: str = "",
    top_k: int = 5,
    top_p: float = 1,
    temperature: float = 1,
    text_split_method: str = "cut5",
    batch_size: int = 1,
    batch_threshold: float = 0.75,
    split_bucket: bool = True,
    speed_factor: float = 1.0,
    fragment_interval: float = 0.3,
    seed: int = -1,
    media_type: str = "wav",
    parallel_infer: bool = True,
    repetition_penalty: float = 1.35,
    sample_steps: int = 32,
    super_sampling: bool = False,
    streaming_mode: Union[bool, int] = False,
    overlap_length: int = 2,
    min_chunk_length: int = 16,
):
    req = {
        "text": text,
        "text_lang": text_lang.lower(),
        "ref_audio_path": ref_audio_path,
        "aux_ref_audio_paths": aux_ref_audio_paths,
        "prompt_text": prompt_text,
        "prompt_lang": prompt_lang.lower(),
        "top_k": top_k,
        "top_p": top_p,
        "temperature": temperature,
        "text_split_method": text_split_method,
        "batch_size": int(batch_size),
        "batch_threshold": float(batch_threshold),
        "speed_factor": float(speed_factor),
        "split_bucket": split_bucket,
        "fragment_interval": fragment_interval,
        "seed": seed,
        "media_type": media_type,
        "streaming_mode": streaming_mode,
        "parallel_infer": parallel_infer,
        "repetition_penalty": float(repetition_penalty),
        "sample_steps": int(sample_steps),
        "super_sampling": super_sampling,
        "overlap_length": int(overlap_length),
        "min_chunk_length": int(min_chunk_length),
    }
    return await tts_handle(req)


@APP.post("/tts")
async def tts_post_endpoint(request: TTS_Request):
    req = request.dict()
    return await tts_handle(req)


@APP.get("/set_refer_audio")
async def set_refer_aduio(refer_audio_path: str = None):

    try:
        tts_pipeline.set_ref_audio(refer_audio_path)
    except Exception as e:
        return JSONResponse(status_code=400, content={"message": "set refer audio failed", "Exception": str(e)})
    return JSONResponse(status_code=200, content={"message": "success"})


# @APP.post("/set_refer_audio")
# async def set_refer_aduio_post(audio_file: UploadFile = File(...)):
#     try:
#         # æ£€æŸ¥æ–‡ä»¶ç±»å‹ï¼Œç¡®ä¿æ˜¯éŸ³é¢‘æ–‡ä»¶
#         if not audio_file.content_type.startswith("audio/"):
#             return JSONResponse(status_code=400, content={"message": "file type is not supported"})

#         os.makedirs("uploaded_audio", exist_ok=True)
#         save_path = os.path.join("uploaded_audio", audio_file.filename)
#         # ä¿å­˜éŸ³é¢‘æ–‡ä»¶åˆ°æœåŠ¡å™¨ä¸Šçš„ä¸€ä¸ªç›®å½•
#         with open(save_path , "wb") as buffer:
#             buffer.write(await audio_file.read())

#         tts_pipeline.set_ref_audio(save_path)
#     except Exception as e:
#         return JSONResponse(status_code=400, content={"message": f"set refer audio failed", "Exception": str(e)})
#     return JSONResponse(status_code=200, content={"message": "success"})


@APP.get("/set_gpt_weights")
async def set_gpt_weights(weights_path: str = None):
    try:
        if weights_path in ["", None]:
            return JSONResponse(status_code=400, content={"message": "gpt weight path is required"})
        tts_pipeline.init_t2s_weights(weights_path)
    except Exception as e:
        return JSONResponse(status_code=400, content={"message": "change gpt weight failed", "Exception": str(e)})

    return JSONResponse(status_code=200, content={"message": "success"})


@APP.get("/set_sovits_weights")
async def set_sovits_weights(weights_path: str = None):
    try:
        if weights_path in ["", None]:
            return JSONResponse(status_code=400, content={"message": "sovits weight path is required"})
        tts_pipeline.init_vits_weights(weights_path)
    except Exception as e:
        return JSONResponse(status_code=400, content={"message": "change sovits weight failed", "Exception": str(e)})
    return JSONResponse(status_code=200, content={"message": "success"})


if __name__ == "__main__":
    try:
        if host == "None":  # åœ¨è°ƒç”¨æ—¶ä½¿ç”¨ -a None å‚æ•°ï¼Œå¯ä»¥è®©apiç›‘å¬åŒæ ˆ
            host = None
        uvicorn.run(app=APP, host=host, port=port, workers=1)
    except Exception:
        traceback.print_exc()
        os.kill(os.getpid(), signal.SIGTERM)
        exit(0)
